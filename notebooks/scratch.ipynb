{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets, linear_model, metrics, preprocessing\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.linear_model import RegressionResults\n",
    "import geopy.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/data'\n",
    "\n",
    "modeling_df = pd.read_csv(\"{}/cleaned_modeling_data.csv\".format(data_dir))\n",
    "\n",
    "pred_df = modeling_df.drop([\"num_testtakers\", \"num_offered\", \"pct_8th_graders_offered\", \"perc_testtakers\", \"perc_testtakers_quartile\"], axis=1)\n",
    "response_df = modeling_df[\"num_testtakers\"].fillna(0)\n",
    "\n",
    "pred_train, pred_test, response_train, response_test = train_test_split(pred_df, response_df, test_size=0.2, random_state=223)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Average ELA Proficiency     2.531893\n",
      "Average Math Proficiency    2.598174\n",
      "dtype: float64\n",
      "Average ELA Proficiency     0.379116\n",
      "Average Math Proficiency    0.478040\n",
      "dtype: float64\n",
      "     Average ELA Proficiency  Average Math Proficiency\n",
      "261                     2.21                      2.14\n",
      "215                     2.27                      2.38\n",
      "160                     2.48                      2.47\n",
      "110                     2.14                      2.01\n",
      "370                     2.24                      2.07\n",
      "303                     2.22                      2.14\n",
      "315                     2.09                      1.98\n",
      "473                     2.36                      2.65\n",
      "220                     2.57                      2.62\n",
      "296                     2.60                      3.13\n",
      "[[-0.85000986 -0.95951067]\n",
      " [-0.69157033 -0.45690096]\n",
      " [-0.13703196 -0.26842232]\n",
      " [-1.03485598 -1.23175759]\n",
      " [-0.7707901  -1.10610517]\n",
      " [-0.82360327 -0.95951067]\n",
      " [-1.16688893 -1.29458381]\n",
      " [-0.45391103  0.10853497]\n",
      " [ 0.10062734  0.04570875]\n",
      " [ 0.1798471   1.11375439]]\n"
     ]
    }
   ],
   "source": [
    "# col_name = \"Economic Need Index\"\n",
    "# print(modeling_df[col_name].describe())\n",
    "# print(modeling_df[col_name].notnull().sum())\n",
    "# print(modeling_df[col_name].isnull().sum())\n",
    "\n",
    "# x_train = pred_train[col_name].to_frame().values\n",
    "# x_test = pred_test[col_name].to_frame().values\n",
    "\n",
    "# plt.xlabel(col_name)\n",
    "# plt.ylabel(\"# Testtakers - 2017\")\n",
    "# plt.scatter(x_train, response_train, alpha = 0.5)\n",
    "# plt.show()\n",
    "\n",
    "# pred_regr = linear_model.LinearRegression()\n",
    "# pred_model = pred_regr.fit(x_train, response_train)\n",
    "\n",
    "# y_pred = regr.predict(x_test)\n",
    "# # The coefficients\n",
    "# print('Coefficients: \\n', pred_regr.coef_)\n",
    "# # The mean squared error\n",
    "# print(\"Mean squared error: %.2f\"\n",
    "#       % mean_squared_error(response_test, y_pred))\n",
    "# # Explained variance score: 1 is perfect prediction\n",
    "# print('Variance score: %.2f' % r2_score(response_test, y_pred))\n",
    "print(type(pred_train))\n",
    "example_cols = pred_train[[\"Average ELA Proficiency\",\"Average Math Proficiency\"]]\n",
    "#preds_to_stdize_train = pred_train[cols_to_standardize].dropna()\n",
    "#print(preds_to_stdize_train.isnull().sum())\n",
    "print(example_cols.mean())\n",
    "print(example_cols.std())\n",
    "#example_col_scaled = preprocessing.scale(example_col)\n",
    "scaler = preprocessing.StandardScaler().fit(pred_train[[\"Average ELA Proficiency\",\"Average Math Proficiency\"]])\n",
    "example_col_scaled = scaler.transform(pred_train[[\"Average ELA Proficiency\",\"Average Math Proficiency\"]])\n",
    "\n",
    "test_scaled = scaler.transform(pred_test[[\"Average ELA Proficiency\",\"Average Math Proficiency\"]])\n",
    "#print(example_col_scaled.std())\n",
    "#print(example_col_scaled.mean())\n",
    "#print(preds_to_stdize_train.mean())\n",
    "print(pred_test[[\"Average ELA Proficiency\",\"Average Math Proficiency\"]][0:10])\n",
    "print(test_scaled[0:10])\n",
    "#scaler = preprocessing.StandardScaler().fit([example_col])\n",
    "#print(scaler.mean_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>num_testtakers</td>  <th>  R-squared:         </th> <td>   0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   140.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 02 Aug 2018</td> <th>  Prob (F-statistic):</th> <td>2.10e-28</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:49:15</td>     <th>  Log-Likelihood:    </th> <td> -2427.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   449</td>      <th>  AIC:               </th> <td>   4858.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   447</td>      <th>  BIC:               </th> <td>   4867.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   43.3719</td> <td>    2.548</td> <td>   17.019</td> <td> 0.000</td> <td>   38.363</td> <td>   48.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   30.2281</td> <td>    2.548</td> <td>   11.861</td> <td> 0.000</td> <td>   25.220</td> <td>   35.237</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>265.085</td> <th>  Durbin-Watson:     </th> <td>   2.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1994.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.522</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>12.010</td>  <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         num_testtakers   R-squared:                       0.239\n",
       "Model:                            OLS   Adj. R-squared:                  0.238\n",
       "Method:                 Least Squares   F-statistic:                     140.7\n",
       "Date:                Thu, 02 Aug 2018   Prob (F-statistic):           2.10e-28\n",
       "Time:                        05:49:15   Log-Likelihood:                -2427.2\n",
       "No. Observations:                 449   AIC:                             4858.\n",
       "Df Residuals:                     447   BIC:                             4867.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         43.3719      2.548     17.019      0.000      38.363      48.380\n",
       "x1            30.2281      2.548     11.861      0.000      25.220      35.237\n",
       "==============================================================================\n",
       "Omnibus:                      265.085   Durbin-Watson:                   2.004\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1994.761\n",
       "Skew:                           2.522   Prob(JB):                         0.00\n",
       "Kurtosis:                      12.010   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sm_x_train = pred_train[[\"borough_bronx\", \"borough_manhattan\", \"borough_queens\", \"borough_staten_island\"]]\n",
    "sm_x_train = example_col_scaled\n",
    "sm_x_train = sm.add_constant(sm_x_train)\n",
    "\n",
    "sm_model = sm.OLS(response_train, sm_x_train, missing='drop')\n",
    "sm_results = sm_model.fit()\n",
    "sm_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pct_black_hispanic\n",
      "SED Code\n",
      "District\n",
      "Latitude\n",
      "Longitude\n",
      "Zip\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         num_testtakers   R-squared:                       0.027\n",
      "Model:                            OLS   Adj. R-squared:                  0.024\n",
      "Method:                 Least Squares   F-statistic:                     12.23\n",
      "Date:                Wed, 01 Aug 2018   Prob (F-statistic):           0.000518\n",
      "Time:                        07:32:33   Log-Likelihood:                -2482.5\n",
      "No. Observations:                 449   AIC:                             4969.\n",
      "Df Residuals:                     447   BIC:                             4977.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    46.6527      3.032     15.388      0.000      40.694      52.611\n",
      "Community School?_Yes   -34.2574      9.797     -3.497      0.001     -53.511     -15.004\n",
      "Community School?_nan          0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                      292.089   Durbin-Watson:                   1.902\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2271.035\n",
      "Skew:                           2.864   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.411   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Economic Need Index\n",
      "Percent ELL\n",
      "Percent Asian\n",
      "Percent Black\n",
      "Percent Hispanic\n",
      "Percent Black / Hispanic\n",
      "Percent White\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/statsmodels/base/model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n",
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1821: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1633: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Attendance Rate\n",
      "Percent of Students Chronically Absent\n",
      "Rigorous Instruction %\n",
      "Collaborative Teachers %\n",
      "Supportive Environment %\n",
      "Effective School Leadership %\n",
      "Strong Family-Community Ties %\n",
      "Trust %\n",
      "Average ELA Proficiency\n",
      "Average Math Proficiency\n",
      "asian_pacific_2016_num_students\n",
      "asian_pacific_2017_num_students\n",
      "avg_math_proficiency_2016\n",
      "avg_math_proficiency_2016_city_diff\n",
      "avg_math_proficiency_2016_comp_diff\n",
      "avg_math_proficiency_2017\n",
      "avg_math_proficiency_2017_city_diff\n",
      "avg_math_proficiency_2017_comp_diff\n",
      "black_2016_avg_ela\n",
      "black_2016_avg_math\n",
      "black_2016_incoming_ela\n",
      "black_2016_incoming_math\n",
      "black_2016_num_students\n",
      "black_2017_avg_ela\n",
      "black_2017_avg_math\n",
      "black_2017_incoming_ela\n",
      "black_2017_incoming_math\n",
      "black_2017_num_students\n",
      "econ_need_index_2016_city_diff\n",
      "econ_need_index_2016_dist_diff\n",
      "econ_need_index_2016_val\n",
      "econ_need_index_2017_city_diff\n",
      "econ_need_index_2017_dist_diff\n",
      "econ_need_index_2017_val\n",
      "grade_7_2015_enrollment\n",
      "grade_7_2016_enrollment\n",
      "grade_7_2017_enrollment\n",
      "grade_8_2015_enrollment\n",
      "grade_8_2016_enrollment\n",
      "grade_8_2017_enrollment\n",
      "hispanic_2016_avg_ela\n",
      "hispanic_2016_avg_math\n",
      "hispanic_2016_incoming_ela\n",
      "hispanic_2016_incoming_math\n",
      "hispanic_2016_num_students\n",
      "hispanic_2017_avg_ela\n",
      "hispanic_2017_avg_math\n",
      "hispanic_2017_incoming_ela\n",
      "hispanic_2017_incoming_math\n",
      "hispanic_2017_num_students\n",
      "incoming_avg_5th_grade_ela_rating_2016_city_diff\n",
      "incoming_avg_5th_grade_ela_rating_2016_dist_diff\n",
      "incoming_avg_5th_grade_ela_rating_2016_val\n",
      "incoming_avg_5th_grade_ela_rating_2017_city_diff\n",
      "incoming_avg_5th_grade_ela_rating_2017_dist_diff\n",
      "incoming_avg_5th_grade_ela_rating_2017_val\n",
      "incoming_avg_5th_grade_math_rating_2016_city_diff\n",
      "incoming_avg_5th_grade_math_rating_2016_dist_diff\n",
      "incoming_avg_5th_grade_math_rating_2016_val\n",
      "incoming_avg_5th_grade_math_rating_2017_city_diff\n",
      "incoming_avg_5th_grade_math_rating_2017_dist_diff\n",
      "incoming_avg_5th_grade_math_rating_2017_val\n",
      "incoming_ela_level_1_2016_city_diff\n",
      "incoming_ela_level_1_2016_dist_diff\n",
      "incoming_ela_level_1_2016_n\n",
      "incoming_ela_level_1_2016_val\n",
      "incoming_ela_level_1_2017_city_diff\n",
      "incoming_ela_level_1_2017_dist_diff\n",
      "incoming_ela_level_1_2017_n\n",
      "incoming_ela_level_1_2017_val\n",
      "incoming_ela_level_2_2016_city_diff\n",
      "incoming_ela_level_2_2016_dist_diff\n",
      "incoming_ela_level_2_2016_n\n",
      "incoming_ela_level_2_2016_val\n",
      "incoming_ela_level_2_2017_city_diff\n",
      "incoming_ela_level_2_2017_dist_diff\n",
      "incoming_ela_level_2_2017_n\n",
      "incoming_ela_level_2_2017_val\n",
      "incoming_ela_level_3_2016_city_diff\n",
      "incoming_ela_level_3_2016_dist_diff\n",
      "incoming_ela_level_3_2016_n\n",
      "incoming_ela_level_3_2016_val\n",
      "incoming_ela_level_3_2017_city_diff\n",
      "incoming_ela_level_3_2017_dist_diff\n",
      "incoming_ela_level_3_2017_n\n",
      "incoming_ela_level_3_2017_val\n",
      "incoming_ela_level_4_2016_city_diff\n",
      "incoming_ela_level_4_2016_dist_diff\n",
      "incoming_ela_level_4_2016_n\n",
      "incoming_ela_level_4_2016_val\n",
      "incoming_ela_level_4_2017_city_diff\n",
      "incoming_ela_level_4_2017_dist_diff\n",
      "incoming_ela_level_4_2017_n\n",
      "incoming_ela_level_4_2017_val\n",
      "incoming_math_level_1_2016_city_diff\n",
      "incoming_math_level_1_2016_dist_diff\n",
      "incoming_math_level_1_2016_n\n",
      "incoming_math_level_1_2016_val\n",
      "incoming_math_level_1_2017_city_diff\n",
      "incoming_math_level_1_2017_dist_diff\n",
      "incoming_math_level_1_2017_n\n",
      "incoming_math_level_1_2017_val\n",
      "incoming_math_level_2_2016_city_diff\n",
      "incoming_math_level_2_2016_dist_diff\n",
      "incoming_math_level_2_2016_n\n",
      "incoming_math_level_2_2016_val\n",
      "incoming_math_level_2_2017_city_diff\n",
      "incoming_math_level_2_2017_dist_diff\n",
      "incoming_math_level_2_2017_n\n",
      "incoming_math_level_2_2017_val\n",
      "incoming_math_level_3_2016_city_diff\n",
      "incoming_math_level_3_2016_dist_diff\n",
      "incoming_math_level_3_2016_n\n",
      "incoming_math_level_3_2016_val\n",
      "incoming_math_level_3_2017_city_diff\n",
      "incoming_math_level_3_2017_dist_diff\n",
      "incoming_math_level_3_2017_n\n",
      "incoming_math_level_3_2017_val\n",
      "incoming_math_level_4_2016_city_diff\n",
      "incoming_math_level_4_2016_dist_diff\n",
      "incoming_math_level_4_2016_n\n",
      "incoming_math_level_4_2016_val\n",
      "incoming_math_level_4_2017_city_diff\n",
      "incoming_math_level_4_2017_dist_diff\n",
      "incoming_math_level_4_2017_n\n",
      "incoming_math_level_4_2017_val\n",
      "pct_8th_graders_w_hs_credit_2016\n",
      "pct_8th_graders_w_hs_credit_2016_city_diff\n",
      "pct_8th_graders_w_hs_credit_2016_comp_diff\n",
      "pct_8th_graders_w_hs_credit_2017\n",
      "pct_8th_graders_w_hs_credit_2017_city_diff\n",
      "pct_8th_graders_w_hs_credit_2017_comp_diff\n",
      "pct_ell_2016_city_diff\n",
      "pct_ell_2016_dist_diff\n",
      "pct_ell_2016_val\n",
      "pct_ell_2017_city_diff\n",
      "pct_ell_2017_dist_diff\n",
      "pct_ell_2017_val\n",
      "pct_hra_assistance_2016_city_diff\n",
      "pct_hra_assistance_2016_dist_diff\n",
      "pct_hra_assistance_2016_val\n",
      "pct_hra_assistance_2017_city_diff\n",
      "pct_hra_assistance_2017_dist_diff\n",
      "pct_hra_assistance_2017_val\n",
      "pct_math_level_3_or_4_2016\n",
      "pct_math_level_3_or_4_2016_city_diff\n",
      "pct_math_level_3_or_4_2016_comp_diff\n",
      "pct_math_level_3_or_4_2017\n",
      "pct_math_level_3_or_4_2017_city_diff\n",
      "pct_math_level_3_or_4_2017_comp_diff\n",
      "pct_poverty_2016_city_diff\n",
      "pct_poverty_2016_dist_diff\n",
      "pct_poverty_2016_val\n",
      "pct_poverty_2017_city_diff\n",
      "pct_poverty_2017_dist_diff\n",
      "pct_poverty_2017_val\n",
      "pct_students_w_disabilities_2016_city_diff\n",
      "pct_students_w_disabilities_2016_dist_diff\n",
      "pct_students_w_disabilities_2016_val\n",
      "pct_students_w_disabilities_2017_city_diff\n",
      "pct_students_w_disabilities_2017_dist_diff\n",
      "pct_students_w_disabilities_2017_val\n",
      "pct_temp_housing_2016_city_diff\n",
      "pct_temp_housing_2016_dist_diff\n",
      "pct_temp_housing_2016_val\n",
      "pct_temp_housing_2017_city_diff\n",
      "pct_temp_housing_2017_dist_diff\n",
      "pct_temp_housing_2017_val\n",
      "sa_attendance_90plus_2016\n",
      "sa_attendance_90plus_2016_city_diff\n",
      "sa_attendance_90plus_2016_dist_diff\n",
      "sa_attendance_90plus_2017\n",
      "sa_attendance_90plus_2017_city_diff\n",
      "sa_attendance_90plus_2017_dist_diff\n",
      "white_2016_num_students\n",
      "white_2017_num_students\n",
      "Community School?_Yes\n",
      "Community School?_nan\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:         num_testtakers   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                  0.000\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Wed, 01 Aug 2018   Prob (F-statistic):                nan\n",
      "Time:                        07:32:35   Log-Likelihood:                -2488.6\n",
      "No. Observations:                 449   AIC:                             4979.\n",
      "Df Residuals:                     448   BIC:                             4983.\n",
      "Df Model:                           0                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "const                    43.3719      2.919     14.859      0.000      37.636      49.108\n",
      "Community School?_nan          0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                      292.682   Durbin-Watson:                   1.889\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2257.604\n",
      "Skew:                           2.877   Prob(JB):                         0.00\n",
      "Kurtosis:                      12.358   Cond. No.                          inf\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is      0. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "Rigorous Instruction Rating_Approaching Target\n",
      "Rigorous Instruction Rating_Exceeding Target\n",
      "Rigorous Instruction Rating_Not Meeting Target\n",
      "Rigorous Instruction Rating_nan\n",
      "Collaborative Teachers Rating_Approaching Target\n",
      "Collaborative Teachers Rating_Exceeding Target\n",
      "Collaborative Teachers Rating_Not Meeting Target\n",
      "Collaborative Teachers Rating_nan\n",
      "Supportive Environment Rating_Approaching Target\n",
      "Supportive Environment Rating_Exceeding Target\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:1554: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return self.ess/self.df_model\n",
      "/Users/greg.bolla/.local/share/virtualenvs/kaggle-passnyc-hqRn-hsS/lib/python3.6/site-packages/pandas/core/indexing.py:1472: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supportive Environment Rating_nan\n",
      "Effective School Leadership Rating_Approaching Target\n",
      "Effective School Leadership Rating_Exceeding Target\n",
      "Effective School Leadership Rating_Not Meeting Target\n",
      "Effective School Leadership Rating_nan\n",
      "Strong Family-Community Ties Rating_Approaching Target\n",
      "Strong Family-Community Ties Rating_Exceeding Target\n",
      "Strong Family-Community Ties Rating_Not Meeting Target\n",
      "Strong Family-Community Ties Rating_nan\n",
      "Trust Rating_Approaching Target\n",
      "Trust Rating_Exceeding Target\n",
      "Trust Rating_Not Meeting Target\n",
      "Trust Rating_nan\n",
      "Student Achievement Rating_Approaching Target\n",
      "Student Achievement Rating_Exceeding Target\n",
      "Student Achievement Rating_Not Meeting Target\n",
      "Student Achievement Rating_nan\n",
      "dist_to_bronx_hs_of_science\n",
      "dist_to_brooklyn_latin_school\n",
      "dist_to_brooklyn_tech_hs\n",
      "dist_to_hs_for_math_sci_eng\n",
      "dist_to_hs_of_amer_studies\n",
      "dist_to_queens_hs_for_sci\n",
      "dist_to_staten_island_tech\n",
      "dist_to_stuyvesant_hs\n",
      "min_dist_to_specialized_school\n"
     ]
    }
   ],
   "source": [
    "invalid_preds = [\"school_name\", \"dbn\", \"Address (Full)\", \"City\", \"Grades\", \"Grade Low\", \"Grade High\", \"SED Code\", \"Latitude\", \"Longitude\", \"Zip\"]\n",
    "\n",
    "numeric_pred_df = pd.DataFrame()\n",
    "cat_pred_df = pd.DataFrame()\n",
    "num_pred_df = pd.DataFrame()\n",
    " \n",
    "for col in pred_train.columns.values:\n",
    "    if col in invalid_preds:\n",
    "        continue\n",
    "    elif pred_train[col].dtype == \"object\":\n",
    "        pred_rows = get_categorical_model(col, pred_train, response_train)\n",
    "        cat_pred_df = cat_pred_df.append(pred_rows, ignore_index=True)\n",
    "    elif pred_train[col].dtype == \"float\":\n",
    "        print(col)\n",
    "        pred_rows = get_numerical_model(col, pred_train, response_train)\n",
    "        num_pred_df = num_pred_df.append(pred_rows, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_model(col_name, pred_train_df, response_train_df):\n",
    "    model_rows = []\n",
    "    \n",
    "    col_list = pred_train_df.columns.values\n",
    "    \n",
    "    col_dummy_vars = [var for var in col_list if \"{}_\".format(col_name) in var]\n",
    "    x_train_df = pred_train_df[col_dummy_vars]\n",
    "    x_train_df = sm.add_constant(x_train_df)\n",
    "\n",
    "    x_model = sm.OLS(response_train_df, x_train_df, missing='drop')\n",
    "    x_results = x_model.fit()\n",
    "    \n",
    "    num_obs = x_results.nobs\n",
    "    r2 = x_results.rsquared\n",
    "    adj_r2 = x_results.rsquared_adj\n",
    "    f_stat = x_results.fvalue\n",
    "    f_stat_pval = x_results.f_pvalue\n",
    "    aic = x_results.aic\n",
    "    bic = x_results.bic\n",
    "    for i, pred_pval in enumerate(x_results.pvalues):\n",
    "        if np.isnan(pred_pval):\n",
    "            print(x_results.summary())\n",
    "            continue\n",
    "        model_row = {}\n",
    "        model_row['model'] = col_name\n",
    "        if len(x_results.pvalues[x_results.pvalues == pred_pval]) > 1:\n",
    "            print(x_results.pvalues[x_results.pvalues == pred_pval])\n",
    "            raise ValueError('multiple preds have same pval')\n",
    "        pred_col = x_results.pvalues[x_results.pvalues == pred_pval].index[0]\n",
    "        pred_coef = x_results.params[pred_col]\n",
    "        \n",
    "        \n",
    "        model_row['model_r2'] = r2\n",
    "        model_row['model_adj_r2'] = adj_r2\n",
    "        model_row['model_f_stat'] = f_stat\n",
    "        model_row['model_f_stat_pval'] = f_stat_pval\n",
    "        model_row['model_aic'] = aic\n",
    "        model_row['model_bic'] = bic\n",
    "        model_row['pred_col'] = pred_col\n",
    "        model_row['pred_coef'] = pred_coef\n",
    "        model_row['pred_col_pval'] = pred_pval\n",
    "        if pred_col != 'const':\n",
    "            model_row['pred_num_miss'] = pred_train_df[pred_col].isnull().sum()\n",
    "        model_rows.append(model_row)\n",
    "\n",
    "    return model_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred_df_cols = [\"model\", \"model_r2\", \"model_adj_r2\", \"model_f_stat\", \"model_f_stat_pval\", \"model_aic\", \"model_bic\",\n",
    "    \"pred_col\", \"pred_coef\", \"pred_col_pval\", \"pred_num_miss\"\n",
    "    ]\n",
    "\n",
    "cat_pred_df = cat_pred_df[cat_pred_df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pred_df.to_csv(\"{}/categorical_single_regression.csv\".format(data_dir), index=False)\n",
    "num_pred_df.to_csv(\"{}/numerical_single_regression.csv\".format(data_dir), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_model(col_name, pred_train_df, response_train_df):\n",
    "    model_rows = []\n",
    "    \n",
    "    x_train_df = pred_train_df[col_name]\n",
    "    x_train_df = sm.add_constant(x_train_df)\n",
    "\n",
    "    x_model = sm.OLS(response_train_df, x_train_df, missing='drop')\n",
    "    x_results = x_model.fit()\n",
    "    \n",
    "    num_obs = x_results.nobs\n",
    "    r2 = x_results.rsquared\n",
    "    adj_r2 = x_results.rsquared_adj\n",
    "    f_stat = x_results.fvalue\n",
    "    f_stat_pval = x_results.f_pvalue\n",
    "    aic = x_results.aic\n",
    "    bic = x_results.bic\n",
    "    for i, pred_pval in enumerate(x_results.pvalues):\n",
    "        if np.isnan(pred_pval):\n",
    "            print(x_results.summary())\n",
    "            continue\n",
    "        model_row = {}\n",
    "        model_row['model'] = col_name\n",
    "        if len(x_results.pvalues[x_results.pvalues == pred_pval]) > 1:\n",
    "            print(x_results.pvalues[x_results.pvalues == pred_pval])\n",
    "            raise ValueError('multiple preds have same pval')\n",
    "        pred_col = x_results.pvalues[x_results.pvalues == pred_pval].index[0]\n",
    "        pred_coef = x_results.params[pred_col]\n",
    "        \n",
    "        \n",
    "        model_row['model_r2'] = r2\n",
    "        model_row['model_adj_r2'] = adj_r2\n",
    "        model_row['model_f_stat'] = f_stat\n",
    "        model_row['model_f_stat_pval'] = f_stat_pval\n",
    "        model_row['model_aic'] = aic\n",
    "        model_row['model_bic'] = bic\n",
    "        model_row['pred_col'] = pred_col\n",
    "        model_row['pred_coef'] = pred_coef\n",
    "        model_row['pred_col_pval'] = pred_pval\n",
    "        if pred_col != 'const':\n",
    "            model_row['pred_num_miss'] = pred_train_df[pred_col].isnull().sum()\n",
    "        model_rows.append(model_row)\n",
    "\n",
    "    return model_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_from_specialized_schools(row):\n",
    "   \n",
    "    row_long_lat = (float(row['Latitude']), float(row['Longitude']))\n",
    "\n",
    "    specialized_school_long_lat = {\n",
    "        \"bronx_hs_of_science\" : (40.87833, -73.89083),\n",
    "        \"brooklyn_latin_school\" : (40.705, -73.9388889),\n",
    "        \"brooklyn_tech_hs\" : (40.6888889, -73.9766667),\n",
    "        \"hs_for_math_sci_eng\" : (40.8215, -73.9490),\n",
    "        \"hs_of_amer_studies\" : (40.8749, -73.8952),\n",
    "        \"queens_hs_for_sci\": (40.699, -73.797),\n",
    "        \"staten_island_tech\" : (40.5676, -74.1181),\n",
    "        \"stuyvesant_hs\" : (40.7178801, -74.0137509)\n",
    "    }\n",
    "    \n",
    "    #dist_df = pd.DataFrame()\n",
    "    row = {}\n",
    "    for specialized_school, specialized_long_lat in specialized_school_long_lat.items():\n",
    "        row[\"dist_to_{}\".format(specialized_school)] = geopy.distance.vincenty(row_long_lat, specialized_long_lat).miles       \n",
    "    row[\"min_dist_to_specialized_school\"] = row[min(row, key=row.get)]\n",
    "    return pd.Series(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = modeling_df.apply(get_dist_from_specialized_schools, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dist_to_bronx_hs_of_science</th>\n",
       "      <th>dist_to_brooklyn_latin_school</th>\n",
       "      <th>dist_to_brooklyn_tech_hs</th>\n",
       "      <th>dist_to_hs_for_math_sci_eng</th>\n",
       "      <th>dist_to_hs_of_amer_studies</th>\n",
       "      <th>dist_to_queens_hs_for_sci</th>\n",
       "      <th>dist_to_staten_island_tech</th>\n",
       "      <th>dist_to_stuyvesant_hs</th>\n",
       "      <th>min_dist_to_specialized_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.275778</td>\n",
       "      <td>6.328220</td>\n",
       "      <td>4.450203</td>\n",
       "      <td>13.670928</td>\n",
       "      <td>17.978016</td>\n",
       "      <td>11.933558</td>\n",
       "      <td>7.300248</td>\n",
       "      <td>6.233516</td>\n",
       "      <td>4.450203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.354160</td>\n",
       "      <td>9.159982</td>\n",
       "      <td>7.650721</td>\n",
       "      <td>16.910698</td>\n",
       "      <td>21.068363</td>\n",
       "      <td>13.207266</td>\n",
       "      <td>6.658060</td>\n",
       "      <td>9.671763</td>\n",
       "      <td>6.658060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.562026</td>\n",
       "      <td>6.708981</td>\n",
       "      <td>7.736581</td>\n",
       "      <td>1.618959</td>\n",
       "      <td>6.236976</td>\n",
       "      <td>11.169889</td>\n",
       "      <td>18.023136</td>\n",
       "      <td>6.297388</td>\n",
       "      <td>1.618959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.051826</td>\n",
       "      <td>3.301437</td>\n",
       "      <td>1.226399</td>\n",
       "      <td>10.471718</td>\n",
       "      <td>14.753907</td>\n",
       "      <td>10.027592</td>\n",
       "      <td>10.065957</td>\n",
       "      <td>3.504831</td>\n",
       "      <td>1.226399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.043313</td>\n",
       "      <td>4.222236</td>\n",
       "      <td>3.942374</td>\n",
       "      <td>6.123651</td>\n",
       "      <td>10.721510</td>\n",
       "      <td>11.193139</td>\n",
       "      <td>13.518514</td>\n",
       "      <td>1.805418</td>\n",
       "      <td>1.805418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dist_to_bronx_hs_of_science  dist_to_brooklyn_latin_school  \\\n",
       "0                    18.275778                       6.328220   \n",
       "1                    21.354160                       9.159982   \n",
       "2                     6.562026                       6.708981   \n",
       "3                    15.051826                       3.301437   \n",
       "4                    11.043313                       4.222236   \n",
       "\n",
       "   dist_to_brooklyn_tech_hs  dist_to_hs_for_math_sci_eng  \\\n",
       "0                  4.450203                    13.670928   \n",
       "1                  7.650721                    16.910698   \n",
       "2                  7.736581                     1.618959   \n",
       "3                  1.226399                    10.471718   \n",
       "4                  3.942374                     6.123651   \n",
       "\n",
       "   dist_to_hs_of_amer_studies  dist_to_queens_hs_for_sci  \\\n",
       "0                   17.978016                  11.933558   \n",
       "1                   21.068363                  13.207266   \n",
       "2                    6.236976                  11.169889   \n",
       "3                   14.753907                  10.027592   \n",
       "4                   10.721510                  11.193139   \n",
       "\n",
       "   dist_to_staten_island_tech  dist_to_stuyvesant_hs  \\\n",
       "0                    7.300248               6.233516   \n",
       "1                    6.658060               9.671763   \n",
       "2                   18.023136               6.297388   \n",
       "3                   10.065957               3.504831   \n",
       "4                   13.518514               1.805418   \n",
       "\n",
       "   min_dist_to_specialized_school  \n",
       "0                        4.450203  \n",
       "1                        6.658060  \n",
       "2                        1.618959  \n",
       "3                        1.226399  \n",
       "4                        1.805418  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df = pd.concat([modeling_df, dist_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_name</th>\n",
       "      <th>dbn</th>\n",
       "      <th>num_testtakers</th>\n",
       "      <th>num_offered</th>\n",
       "      <th>pct_8th_graders_offered</th>\n",
       "      <th>pct_black_hispanic</th>\n",
       "      <th>SED Code</th>\n",
       "      <th>District</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Student Achievement Rating_nan</th>\n",
       "      <th>dist_to_bronx_hs_of_science</th>\n",
       "      <th>dist_to_brooklyn_latin_school</th>\n",
       "      <th>dist_to_brooklyn_tech_hs</th>\n",
       "      <th>dist_to_hs_for_math_sci_eng</th>\n",
       "      <th>dist_to_hs_of_amer_studies</th>\n",
       "      <th>dist_to_queens_hs_for_sci</th>\n",
       "      <th>dist_to_staten_island_tech</th>\n",
       "      <th>dist_to_stuyvesant_hs</th>\n",
       "      <th>min_dist_to_specialized_school</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>THE CHRISTA MCAULIFFE SCHOOL\\I.S. 187</td>\n",
       "      <td>20K187</td>\n",
       "      <td>251.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.320000e+11</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.627847</td>\n",
       "      <td>-74.004003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.275778</td>\n",
       "      <td>6.328220</td>\n",
       "      <td>4.450203</td>\n",
       "      <td>13.670928</td>\n",
       "      <td>17.978016</td>\n",
       "      <td>11.933558</td>\n",
       "      <td>7.300248</td>\n",
       "      <td>6.233516</td>\n",
       "      <td>4.450203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MARK TWAIN I.S. 239 FOR THE GIFTED &amp; TALENTED</td>\n",
       "      <td>21K239</td>\n",
       "      <td>336.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.13</td>\n",
       "      <td>3.321000e+11</td>\n",
       "      <td>21.0</td>\n",
       "      <td>40.578660</td>\n",
       "      <td>-73.992391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.354160</td>\n",
       "      <td>9.159982</td>\n",
       "      <td>7.650721</td>\n",
       "      <td>16.910698</td>\n",
       "      <td>21.068363</td>\n",
       "      <td>13.207266</td>\n",
       "      <td>6.658060</td>\n",
       "      <td>9.671763</td>\n",
       "      <td>6.658060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.H.S. 054 BOOKER T. WASHINGTON</td>\n",
       "      <td>03M054</td>\n",
       "      <td>257.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.23</td>\n",
       "      <td>3.103000e+11</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.800512</td>\n",
       "      <td>-73.962802</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.562026</td>\n",
       "      <td>6.708981</td>\n",
       "      <td>7.736581</td>\n",
       "      <td>1.618959</td>\n",
       "      <td>6.236976</td>\n",
       "      <td>11.169889</td>\n",
       "      <td>18.023136</td>\n",
       "      <td>6.297388</td>\n",
       "      <td>1.618959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M.S. 51 WILLIAM ALEXANDER</td>\n",
       "      <td>15K051</td>\n",
       "      <td>280.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.28</td>\n",
       "      <td>3.315000e+11</td>\n",
       "      <td>15.0</td>\n",
       "      <td>40.672180</td>\n",
       "      <td>-73.984625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.051826</td>\n",
       "      <td>3.301437</td>\n",
       "      <td>1.226399</td>\n",
       "      <td>10.471718</td>\n",
       "      <td>14.753907</td>\n",
       "      <td>10.027592</td>\n",
       "      <td>10.065957</td>\n",
       "      <td>3.504831</td>\n",
       "      <td>1.226399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK CITY LAB MIDDLE SCHOOL FOR COLLABORAT...</td>\n",
       "      <td>02M312</td>\n",
       "      <td>163.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>3.102000e+11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>40.742571</td>\n",
       "      <td>-74.002371</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.043313</td>\n",
       "      <td>4.222236</td>\n",
       "      <td>3.942374</td>\n",
       "      <td>6.123651</td>\n",
       "      <td>10.721510</td>\n",
       "      <td>11.193139</td>\n",
       "      <td>13.518514</td>\n",
       "      <td>1.805418</td>\n",
       "      <td>1.805418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         school_name     dbn  num_testtakers  \\\n",
       "0              THE CHRISTA MCAULIFFE SCHOOL\\I.S. 187  20K187           251.0   \n",
       "1      MARK TWAIN I.S. 239 FOR THE GIFTED & TALENTED  21K239           336.0   \n",
       "2                    J.H.S. 054 BOOKER T. WASHINGTON  03M054           257.0   \n",
       "3                          M.S. 51 WILLIAM ALEXANDER  15K051           280.0   \n",
       "4  NEW YORK CITY LAB MIDDLE SCHOOL FOR COLLABORAT...  02M312           163.0   \n",
       "\n",
       "   num_offered  pct_8th_graders_offered  pct_black_hispanic      SED Code  \\\n",
       "0        205.0                     0.75                0.08  3.320000e+11   \n",
       "1        196.0                     0.46                0.13  3.321000e+11   \n",
       "2        150.0                     0.53                0.23  3.103000e+11   \n",
       "3        122.0                     0.33                0.28  3.315000e+11   \n",
       "4        113.0                     0.62                0.08  3.102000e+11   \n",
       "\n",
       "   District   Latitude  Longitude               ...                \\\n",
       "0      20.0  40.627847 -74.004003               ...                 \n",
       "1      21.0  40.578660 -73.992391               ...                 \n",
       "2       3.0  40.800512 -73.962802               ...                 \n",
       "3      15.0  40.672180 -73.984625               ...                 \n",
       "4       2.0  40.742571 -74.002371               ...                 \n",
       "\n",
       "  Student Achievement Rating_nan dist_to_bronx_hs_of_science  \\\n",
       "0                            0.0                   18.275778   \n",
       "1                            0.0                   21.354160   \n",
       "2                            0.0                    6.562026   \n",
       "3                            0.0                   15.051826   \n",
       "4                            0.0                   11.043313   \n",
       "\n",
       "   dist_to_brooklyn_latin_school dist_to_brooklyn_tech_hs  \\\n",
       "0                       6.328220                 4.450203   \n",
       "1                       9.159982                 7.650721   \n",
       "2                       6.708981                 7.736581   \n",
       "3                       3.301437                 1.226399   \n",
       "4                       4.222236                 3.942374   \n",
       "\n",
       "  dist_to_hs_for_math_sci_eng  dist_to_hs_of_amer_studies  \\\n",
       "0                   13.670928                   17.978016   \n",
       "1                   16.910698                   21.068363   \n",
       "2                    1.618959                    6.236976   \n",
       "3                   10.471718                   14.753907   \n",
       "4                    6.123651                   10.721510   \n",
       "\n",
       "  dist_to_queens_hs_for_sci  dist_to_staten_island_tech  \\\n",
       "0                 11.933558                    7.300248   \n",
       "1                 13.207266                    6.658060   \n",
       "2                 11.169889                   18.023136   \n",
       "3                 10.027592                   10.065957   \n",
       "4                 11.193139                   13.518514   \n",
       "\n",
       "   dist_to_stuyvesant_hs  min_dist_to_specialized_school  \n",
       "0               6.233516                        4.450203  \n",
       "1               9.671763                        6.658060  \n",
       "2               6.297388                        1.618959  \n",
       "3               3.504831                        1.226399  \n",
       "4               1.805418                        1.805418  \n",
       "\n",
       "[5 rows x 246 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "\"Average ELA Proficiency\", \n",
    "\"Average Math Proficiency\",\n",
    "\"sa_attendance_90plus_2017\" , \n",
    "\"min_dist_to_specialized_school\",\n",
    "\"Student Achievement Rating_Approaching Target\",\n",
    "\"Student Achievement Rating_Exceeding Target\",\n",
    "\"Student Achievement Rating_Not Meeting Target\",\n",
    "\"Student Achievement Rating_nan\",\n",
    "\"Strong Family-Community Ties Rating_Approaching Target\",\n",
    "\"Strong Family-Community Ties Rating_Exceeding Target\",\n",
    "\"Strong Family-Community Ties Rating_Not Meeting Target\",\n",
    "\"Strong Family-Community Ties Rating_nan\",\n",
    "\"pct_8th_graders_w_hs_credit_2017\",\n",
    "\"borough_bronx\",\n",
    "\"borough_manhattan\",\n",
    "\"borough_queens\",\n",
    "\"borough_staten_island\"\n",
    "]\n",
    "\n",
    "cols_to_standardize = [\n",
    "    \"Average ELA Proficiency\", \n",
    "    \"Average Math Proficiency\",\n",
    "    \"sa_attendance_90plus_2017\",\n",
    "    \"min_dist_to_specialized_school\",\n",
    "    \"pct_8th_graders_w_hs_credit_2017\"\n",
    "]\n",
    "#x_train = pred_train[preds]\n",
    "\n",
    "#len(x_train.dropna())\n",
    "#mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(x_train, response_train)\n",
    " \n",
    "\n",
    "#sm_x_train = sm.add_constant(sm_x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetted_modeling_df = modeling_df[]\n",
    "\n",
    "subsetted_modeling_df = subsetted_modeling_df.dropna()\n",
    "subsetted_pred_df = subsetted_modeling_df[preds]\n",
    "subsetted_response_df = subsetted_modeling_df[\"perc_testtakers_quartile\"]\n",
    "subsetted_pred_train, subsetted_pred_test, subsetted_response_train, subsetted_response_test = train_test_split(subsetted_pred_df, subsetted_response_df, test_size=0.2, random_state=223)\n",
    "\n",
    "\n",
    "#multinom_response_df = modeling_df[\"perc_testtakers_quartile\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_lr = linear_model.LogisticRegression(multi_class='multinomial', solver='newton-cg').fit(subsetted_pred_train, subsetted_response_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression Train Accuracy ::  0.4964871194379391\n",
      "Logistic regression Test Accuracy ::  0.48598130841121495\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression Train Accuracy :: \", metrics.accuracy_score(subsetted_response_train, mul_lr.predict(subsetted_pred_train)))\n",
    "print(\"Logistic regression Test Accuracy :: \", metrics.accuracy_score(subsetted_response_test, mul_lr.predict(subsetted_pred_test)))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4. 4. 1. 2. 1. 2. 1. 1. 4. 1. 4. 1. 4. 1. 2. 1. 2. 4. 1. 1. 4. 4. 1. 1.\n",
      " 1. 3. 2. 1. 4. 2. 3. 4. 3. 1. 4. 1. 4. 3. 1. 2. 1. 1. 3. 1. 3. 1. 1. 4.\n",
      " 3. 4. 1. 1. 2. 1. 4. 2. 1. 4. 3. 3. 3. 2. 3. 1. 1. 4. 1. 3. 4. 3. 3. 1.\n",
      " 3. 1. 1. 2. 4. 4. 4. 3. 4. 1. 4. 4. 1. 4. 3. 4. 1. 4. 4. 2. 2. 1. 4. 4.\n",
      " 2. 3. 4. 3. 1. 1. 2. 2. 4. 4. 3. 1. 1. 1. 1. 3. 2. 2. 2. 2. 2. 2. 3. 2.\n",
      " 2. 4. 2. 1. 2. 4. 2. 4. 2. 1. 1. 1. 1. 4. 4. 3. 1. 4. 1. 1. 4. 2. 4. 1.\n",
      " 4. 4. 3. 1. 4. 1. 2. 2. 2. 4. 3. 1. 4. 4. 2. 3. 1. 3. 4. 1. 3. 1. 1. 4.\n",
      " 4. 2. 2. 2. 4. 1. 4. 1. 4. 1. 1. 2. 2. 2. 2. 4. 2. 3. 4. 2. 3. 1. 3. 4.\n",
      " 1. 4. 1. 3. 2. 1. 3. 3. 2. 1. 4. 1. 4. 1. 4. 1. 4. 4. 2. 1. 3. 3. 4. 2.\n",
      " 4. 1. 4. 2. 1. 2. 1. 3. 2. 1. 1. 4. 1. 2. 1. 3. 2. 3. 3. 1. 4. 2. 4. 4.\n",
      " 2. 1. 1. 4. 3. 4. 2. 1. 1. 4. 3. 1. 2. 2. 4. 4. 3. 1. 1. 2. 2. 4. 2. 1.\n",
      " 4. 1. 4. 1. 4. 1. 1. 4. 2. 3. 1. 1. 4. 1. 2. 3. 4. 3. 4. 4. 1. 2. 1. 4.\n",
      " 4. 2. 4. 2. 2. 3. 4. 1. 2. 1. 4. 2. 1. 4. 2. 2. 1. 3. 4. 2. 2. 4. 2. 2.\n",
      " 2. 1. 1. 1. 2. 3. 1. 1. 4. 4. 1. 1. 3. 2. 4. 1. 2. 1. 1. 1. 4. 1. 2. 4.\n",
      " 2. 1. 4. 3. 1. 1. 4. 1. 4. 4. 3. 3. 3. 1. 3. 3. 2. 4. 3. 1. 3. 2. 1. 1.\n",
      " 2. 1. 3. 2. 2. 2. 4. 2. 1. 1. 4. 4. 1. 4. 4. 4. 3. 1. 2. 1. 3. 4. 4. 1.\n",
      " 1. 3. 3. 3. 3. 2. 1. 4. 4. 4. 4. 1. 4. 4. 1. 4. 1. 3. 2. 1. 3. 2. 1. 3.\n",
      " 1. 1. 1. 2. 2. 3. 1. 3. 4. 2. 4. 4. 4. 4. 2. 3. 3. 4. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(mul_lr.predict(subsetted_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6      4.0\n",
      "153    1.0\n",
      "345    2.0\n",
      "160    1.0\n",
      "166    1.0\n",
      "451    3.0\n",
      "156    1.0\n",
      "349    4.0\n",
      "322    4.0\n",
      "326    2.0\n",
      "39     3.0\n",
      "203    1.0\n",
      "64     4.0\n",
      "492    4.0\n",
      "56     3.0\n",
      "317    2.0\n",
      "301    2.0\n",
      "342    2.0\n",
      "475    3.0\n",
      "249    1.0\n",
      "66     3.0\n",
      "285    3.0\n",
      "292    1.0\n",
      "455    2.0\n",
      "254    1.0\n",
      "60     3.0\n",
      "294    2.0\n",
      "307    1.0\n",
      "162    3.0\n",
      "35     4.0\n",
      "      ... \n",
      "27     4.0\n",
      "199    2.0\n",
      "515    4.0\n",
      "351    3.0\n",
      "104    3.0\n",
      "187    1.0\n",
      "149    1.0\n",
      "450    3.0\n",
      "338    2.0\n",
      "315    1.0\n",
      "434    4.0\n",
      "172    1.0\n",
      "214    1.0\n",
      "232    2.0\n",
      "481    3.0\n",
      "403    2.0\n",
      "116    1.0\n",
      "272    1.0\n",
      "98     4.0\n",
      "14     4.0\n",
      "408    4.0\n",
      "76     4.0\n",
      "206    3.0\n",
      "284    4.0\n",
      "159    1.0\n",
      "454    2.0\n",
      "177    1.0\n",
      "112    3.0\n",
      "17     4.0\n",
      "483    1.0\n",
      "Name: perc_testtakers_quartile, Length: 427, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(subsetted_response_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BROOKLYN               185\n",
       "BRONX                  137\n",
       "NEW YORK               115\n",
       "STATEN ISLAND           17\n",
       "JAMAICA                 14\n",
       "FLUSHING                13\n",
       "LONG ISLAND CITY        10\n",
       "FAR ROCKAWAY             6\n",
       "SPRINGFIELD GARDENS      5\n",
       "ROCKAWAY PARK            4\n",
       "ELMHURST                 4\n",
       "MIDDLE VILLAGE           4\n",
       "ASTORIA                  4\n",
       "JACKSON HEIGHTS          3\n",
       "BAYSIDE                  3\n",
       "OZONE PARK               3\n",
       "HOWARD BEACH             3\n",
       "QUEENS VILLAGE           2\n",
       "ROSEDALE                 2\n",
       "GLENDALE                 2\n",
       "RIDGEWOOD                2\n",
       "REGO PARK                2\n",
       "SOUTH OZONE PARK         2\n",
       "EAST ELMHURST            2\n",
       "ARVERNE                  2\n",
       "SAINT ALBANS             2\n",
       "BELLEROSE                2\n",
       "FOREST HILLS             1\n",
       "ROCKAWAY BEACH           1\n",
       "MASPETH                  1\n",
       "ROOSEVELT ISLAND         1\n",
       "CORONA                   1\n",
       "CAMBRIA HEIGHTS          1\n",
       "FLORAL PARK              1\n",
       "HOLLIS                   1\n",
       "WHITESTONE               1\n",
       "LITTLE NECK              1\n",
       "BROAD CHANNEL            1\n",
       "WOODSIDE                 1\n",
       "Name: City, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeling_df.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = \"Average ELA Proficiency\"\n",
    "pred_train[col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
